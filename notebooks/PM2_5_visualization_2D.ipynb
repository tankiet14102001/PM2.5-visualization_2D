{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNw1XFQrWUXkkf+khWSZBXs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tankiet14102001/PM2.5-visualization_2D/blob/main/PM2_5_visualization_2D.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GuEfRbx6k-58",
        "outputId": "99c2b694-18e8-4f58-c154-e586e5736af9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['2023-딱2-01.txt',\n",
              " '2024-01-08 (1).txt',\n",
              " '2023-11-24.txt',\n",
              " '2023-11-25.txt',\n",
              " '2023-11-29.txt',\n",
              " '2023-12-02_DH.txt',\n",
              " '2023-11-30.txt',\n",
              " '2023-12-02.txt',\n",
              " '2023-11-27.txt',\n",
              " '2023-11-28.txt',\n",
              " '2023-11-26.txt',\n",
              " '2023-12-05.txt',\n",
              " '2023-12-07.txt',\n",
              " '2023-12-15.txt',\n",
              " '2023-12-14.txt',\n",
              " '2023-12-17.txt',\n",
              " '2023-12-21.txt',\n",
              " '2023-12-22.txt',\n",
              " '2023-12-24.txt',\n",
              " '2024-01-01.txt',\n",
              " '2023-12-26.txt',\n",
              " '2024-01-04.txt',\n",
              " '2024-01-05.txt',\n",
              " '2024-01-08.txt',\n",
              " '2024-01-11.txt',\n",
              " '2024-01-12.txt',\n",
              " '2024-01-05_1.txt',\n",
              " '2024-01-05_2.txt',\n",
              " '2024-01-05_3.txt',\n",
              " '2024-01-05_4.txt',\n",
              " '2024-01-12_1.txt',\n",
              " '2024-01-12_2.txt',\n",
              " '2024-01-12_3.txt',\n",
              " '2024-01-12_4.txt',\n",
              " 'cleaned_data_file.txt',\n",
              " 'filtered_data',\n",
              " '2024-01-15.txt',\n",
              " '2024-01-22.txt',\n",
              " '2024-01-26.txt',\n",
              " '2024-02-04.txt',\n",
              " '2024-01-01_filtered_data_map.html']"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)\n",
        "\n",
        "import os\n",
        "\n",
        "# CHANGE THIS BELOW PATHS TO YOUR OWN DRIVE PATH CONTAINED YOUR FOLDER DATASET\n",
        "path = '/content/gdrive/My Drive/Colab Notebooks/projects/thesis_dust-box_from-20240106/data/BKbox/'\n",
        "os.chdir(path)\n",
        "os.listdir()  # current folder structure in top layer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "file_name = '2023-12-26';\n",
        "\n",
        "# Define the wanted columns\n",
        "#wanted_columns = ['DateTime', 'Temp', 'Humi', 'PM1_0', 'PM2_5', 'PM10', 'Lat', 'Long']\n",
        "wanted_columns = ['DateTime', 'Temp', 'Humi', 'PM1_0', 'PM2_5', 'PM10', 'Lat', 'Long', 'Alt']\n",
        "\n",
        "# Load the data into a DataFrame\n",
        "try:\n",
        "  df = pd.read_csv(file_name + '.txt', sep=',', encoding='latin1', error_bad_lines=False)\n",
        "except pd.errors.ParserError as e:\n",
        "  print(\"ParserError:\", e)\n",
        "  df = pd.DataFrame() # Create an empty DataFrame in case of error\n",
        "\n",
        "print(df)\n",
        "\n",
        "if not df.empty:\n",
        "    # Select only the wanted columns\n",
        "    if set(wanted_columns).issubset(df.columns):\n",
        "        df = df[wanted_columns]\n",
        "    else:\n",
        "        missing_columns = set(wanted_columns) - set(df.columns)\n",
        "        print(f\"Missing columns: {missing_columns}\")\n",
        "\n",
        "\"\"\"\n",
        "file_name = '2023-12-07'\n",
        "lines = []\n",
        "with open(file_name + '.txt', 'r', encoding='latin1') as file:\n",
        "    for line in file:\n",
        "        try:\n",
        "            lines.append(line)\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing line: {e}\")\n",
        "\n",
        "# Create a DataFrame from the processed lines\n",
        "df = pd.DataFrame(lines)\n",
        "df = pd.read_csv(pd.Series(df[0]), sep=',')\n",
        "\"\"\"\n",
        "\"\"\"\n",
        "\n",
        "import pandas as pd\n",
        "\"\"\"\n",
        "\"\"\"\n",
        "\n",
        "file_name = '2023-12-05';\n",
        "\n",
        "# Load data from the CSV file with error handling\n",
        "try:\n",
        "    df = pd.read_csv(file_name + '.txt', sep=',', encoding='latin1')\n",
        "except pd.errors.ParserError as e:\n",
        "    print(\"ParserError:\", e)\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "# Select only the wanted columns\n",
        "df = df[wanted_columns]\n",
        "\"\"\"\n",
        "\n",
        "# Define a function to check for invalid characters in a row\n",
        "def has_invalid_characters(row):\n",
        "    for value in row:\n",
        "        if re.search(r'[^a-zA-Z0-9:.,\\-_ ]', str(value)):\n",
        "            return True\n",
        "    return False\n",
        "\n",
        "# Filter out rows with invalid characters\n",
        "df = df[~df.apply(has_invalid_characters, axis=1)]\n",
        "\n",
        "print(df)\n",
        "# Print the resulting DataFrame\n",
        "print(df.head())"
      ],
      "metadata": {
        "id": "kYuVCxelmbZ3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d0c27208-126c-4767-b8ff-d23ec53181e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-7dbe65aa38aa>:12: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
            "\n",
            "\n",
            "  df = pd.read_csv(file_name + '.txt', sep=',', encoding='latin1', error_bad_lines=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    DeviceName             DateTime  Temp  Humi     Press PM1_0 PM2_5 PM10  \\\n",
            "0      SPARC-1  2023-12-26T07:08:38  24.3  63.9  1.001226    24    35   43   \n",
            "1      SPARC-1  2023-12-26T07:08:45  24.4  62.0  1.001227    26    35   44   \n",
            "2      SPARC-1  2023-12-26T07:08:52  24.4  61.9  1.001227    24    34   42   \n",
            "3      SPARC-1  2023-12-26T07:08:58  24.4  61.8  1.001224    23    35   39   \n",
            "4      SPARC-1  2023-12-26T07:09:05  24.5  61.7  1.001226    23    35   39   \n",
            "..         ...                  ...   ...   ...       ...   ...   ...  ...   \n",
            "537    SPARC-1  2023-12-26T08:10:25  31.0  42.6  1.001912    12    17   18   \n",
            "538    SPARC-1  2023-12-26T08:10:32  31.0  42.5  1.001889    13    18   20   \n",
            "539    SPARC-1  2023-12-26T08:10:39  31.0  42.4  1.001864    22    29   32   \n",
            "540   §SPARC-1  2023-12-26T08:10:\u00066  31.0  42.1  1.001849    32    45   55   \n",
            "541    SPARC-1  2023-12-26T08:10:53  31.1  42.0  1.001832    35    51   61   \n",
            "\n",
            "          Bat        Lat        Long         Alt  \n",
            "0    1.916782   0.000000    0.000000    0.000000  \n",
            "1    1.910234   0.000000    0.000000    0.000000  \n",
            "2    1.894689   0.000000    0.000000    0.000000  \n",
            "3    1.887329   0.000000    0.000000    0.000000  \n",
            "4    1.893053   0.000000    0.000000    0.000000  \n",
            "..        ...        ...         ...         ...  \n",
            "537  1.893053  10.800774  106.640842  -17.700000  \n",
            "538  1.893053  10.800779  106.640772  Þ14.200000  \n",
            "539  1.857915  10.800759  106.640754   -8.400000  \n",
            "540  1.856282  10.800719  106.640749   -2.200000  \n",
            "541  1.899597  10.800707  106.640735    3.300000  \n",
            "\n",
            "[542 rows x 12 columns]\n",
            "                DateTime  Temp  Humi PM1_0 PM2_5 PM10        Lat        Long  \\\n",
            "0    2023-12-26T07:08:38  24.3  63.9    24    35   43   0.000000    0.000000   \n",
            "1    2023-12-26T07:08:45  24.4  62.0    26    35   44   0.000000    0.000000   \n",
            "2    2023-12-26T07:08:52  24.4  61.9    24    34   42   0.000000    0.000000   \n",
            "3    2023-12-26T07:08:58  24.4  61.8    23    35   39   0.000000    0.000000   \n",
            "4    2023-12-26T07:09:05  24.5  61.7    23    35   39   0.000000    0.000000   \n",
            "..                   ...   ...   ...   ...   ...  ...        ...         ...   \n",
            "535  2023-12-26T08:10:11  30.9  42.9    16    20   22  10.800828  106.640917   \n",
            "536  2023-12-26T08:10:18  30.9  42.7    15    20   20  10.800817  106.640875   \n",
            "537  2023-12-26T08:10:25  31.0  42.6    12    17   18  10.800774  106.640842   \n",
            "539  2023-12-26T08:10:39  31.0  42.4    22    29   32  10.800759  106.640754   \n",
            "541  2023-12-26T08:10:53  31.1  42.0    35    51   61  10.800707  106.640735   \n",
            "\n",
            "            Alt  \n",
            "0      0.000000  \n",
            "1      0.000000  \n",
            "2      0.000000  \n",
            "3      0.000000  \n",
            "4      0.000000  \n",
            "..          ...  \n",
            "535  -25.000000  \n",
            "536  -23.200000  \n",
            "537  -17.700000  \n",
            "539   -8.400000  \n",
            "541    3.300000  \n",
            "\n",
            "[488 rows x 9 columns]\n",
            "              DateTime  Temp  Humi PM1_0 PM2_5 PM10       Lat      Long  \\\n",
            "0  2023-12-26T07:08:38  24.3  63.9    24    35   43  0.000000  0.000000   \n",
            "1  2023-12-26T07:08:45  24.4  62.0    26    35   44  0.000000  0.000000   \n",
            "2  2023-12-26T07:08:52  24.4  61.9    24    34   42  0.000000  0.000000   \n",
            "3  2023-12-26T07:08:58  24.4  61.8    23    35   39  0.000000  0.000000   \n",
            "4  2023-12-26T07:09:05  24.5  61.7    23    35   39  0.000000  0.000000   \n",
            "\n",
            "        Alt  \n",
            "0  0.000000  \n",
            "1  0.000000  \n",
            "2  0.000000  \n",
            "3  0.000000  \n",
            "4  0.000000  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the directory and file name for the new file\n",
        "output_directory = '/content/gdrive/My Drive/Colab Notebooks/projects/thesis_dust-box_from-20240106/data/BKbox/filtered_data/'\n",
        "output_file_name = file_name + '_filtered_data.txt'\n",
        "\n",
        "# Save the filtered DataFrame to a new CSV file\n",
        "df.to_csv(output_directory + output_file_name, index=False)\n",
        "\n",
        "print(\"Filtered data has been saved to:\", output_directory + output_file_name)\n"
      ],
      "metadata": {
        "id": "NcJTT7uTmbW2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92e12c1f-8370-4ba0-ce00-9d0dd03d1248"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Filtered data has been saved to: /content/gdrive/My Drive/Colab Notebooks/projects/thesis_dust-box_from-20240106/data/BKbox/filtered_data/2023-12-26_filtered_data.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import folium\n",
        "import pandas as pd\n",
        "\n",
        "# Define the AQI dictionary\n",
        "aqi = {\n",
        "    'Good': {'pm2.5': [0, 12], 'color': '#006400'},\n",
        "    'Moderate': {'pm2.5': [12.1, 35.4], 'color': '#FFD700'},\n",
        "    'Unhealthy for Sensitive Groups': {'pm2.5': [35.5, 55.4], 'color': '#FF8C00'},\n",
        "    'Unhealthy': {'pm2.5': [55.5, 150.4], 'color': 'red'},\n",
        "    'Very Unhealthy': {'pm2.5': [150.5, 250.5], 'color': 'purple'},\n",
        "    'Hazardous': {'pm2.5': [250.5, 500.4], 'color': 'maroon'}\n",
        "}\n",
        "\"\"\"\n",
        "# Load data from the CSV file with error handling\n",
        "try:\n",
        "    df = pd.read_csv('2023-12-05.txt', sep=',', encoding='latin1')\n",
        "except pd.errors.ParserError as e:\n",
        "    print(\"ParserError:\", e)\n",
        "\"\"\"\n",
        "\n",
        "\"\"\"\n",
        "# Keep only the desired columns\n",
        "df = df[['DateTime', 'Temp', 'Humi', 'PM2_5', 'Lat', 'Long', 'Alt']]\n",
        "\"\"\"\n",
        "\n",
        "# Remove rows with invalid PM2_5 data\n",
        "df = df[df['PM2_5'].apply(lambda x: str(x).replace('.', '').isdigit())]\n",
        "df['PM2_5'] = pd.to_numeric(df['PM2_5'], errors='coerce')\n",
        "\n",
        "# Convert latitude and longitude columns to numeric\n",
        "df['Lat'] = pd.to_numeric(df['Lat'], errors='coerce')\n",
        "df['Long'] = pd.to_numeric(df['Long'], errors='coerce')\n",
        "\n",
        "# Remove rows with NaN values in Lat and Long\n",
        "df = df.dropna(subset=['Lat', 'Long'])\n",
        "\n",
        "# Create a map centered at the mean latitude and longitude of your data\n",
        "map_center = [df['Lat'].mean(), df['Long'].mean()]\n",
        "mymap = folium.Map(location=map_center, zoom_start=10)\n",
        "\n",
        "\n",
        "\n",
        "# Add markers for each data point with PM2.5 data displayed inside the circle marker\n",
        "for index, row in df.iterrows():\n",
        "    # Determine the AQI category based on PM2.5 value\n",
        "    pm2_5 = row['PM2_5']\n",
        "    aqi_category = None\n",
        "    for category, data in aqi.items():\n",
        "        if pm2_5 >= data['pm2.5'][0] and pm2_5 <= data['pm2.5'][1]:\n",
        "            aqi_category = category\n",
        "            break\n",
        "\n",
        "    # Determine marker color based on AQI category\n",
        "    marker_color = aqi[aqi_category]['color']\n",
        "\n",
        "    # Add CircleMarker with the specified radius\n",
        "    folium.CircleMarker(\n",
        "        location=[row['Lat'], row['Long']],\n",
        "        radius=5,  # Adjust the size of the marker\n",
        "        color=marker_color,\n",
        "        fill=True,\n",
        "        fill_color=marker_color,\n",
        "        fill_opacity=1,\n",
        "        popup=f\"PM2.5: {pm2_5}, AQI: {aqi_category}\"\n",
        "    ).add_to(mymap)\n",
        "\n",
        "    # Add text to display PM2.5 value inside the circle marker\n",
        "    folium.Marker(\n",
        "        location=[row['Lat'], row['Long']],\n",
        "        icon=folium.DivIcon(\n",
        "            icon_size=(50, 50),\n",
        "            icon_anchor=(25, 25),\n",
        "            #html=f\"<div style='display: flex; justify-content: center; align-items: center; width: 100%; height: 100%; color: black; font-size: 8px;'>{pm2_5}</div>\",\n",
        "        )\n",
        "    ).add_to(mymap)\n",
        "\n",
        "# Add a legend for AQI categories\n",
        "legend_html = \"\"\"\n",
        "     <div style=\"position: fixed;\n",
        "                 bottom: 50px; left: 50px; width: 200px; height: 200px;\n",
        "                 border:2px solid grey; z-index:9999; font-size:14px;\n",
        "                 background-color:white; opacity: 0.9;\n",
        "                 \">\n",
        "     &nbsp; AQI Legend <br>\n",
        "     &nbsp; Good: <i class=\"fas fa-circle\" style=\"color:#006400; font-size: 24px;\"></i><br>\n",
        "     &nbsp; Moderate: <i class=\"fas fa-circle\" style=\"color:#FFD700; font-size: 24px;\"></i><br>\n",
        "     &nbsp; Unhealthy for Sensitive Groups: <i class=\"fas fa-circle\" style=\"color:#FF8C00; font-size: 24px;\"></i><br>\n",
        "     &nbsp; Unhealthy: <i class=\"fas fa-circle\" style=\"color:red; font-size: 24px;\"></i><br>\n",
        "     &nbsp; Very Unhealthy: <i class=\"fas fa-circle\" style=\"color:purple; font-size: 24px;\"></i><br>\n",
        "     &nbsp; Hazardous: <i class=\"fas fa-circle\" style=\"color:maroon; font-size: 24px;\"></i><br>\n",
        "      </div>\n",
        "     \"\"\"\n",
        "mymap.get_root().html.add_child(folium.Element(legend_html))\n",
        "\n",
        "# Save the map as an HTML file\n",
        "mymap.save(\"/content/gdrive/My Drive/Colab Notebooks/projects/thesis_dust-box_from-20240106/graph/\" + file_name + \"_filtered_data_map.html\")\n"
      ],
      "metadata": {
        "id": "6qkrCZx6mbIn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e502204-0312-4c4a-e563-95eda0af712a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-2bf89ac340d1>:28: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['PM2_5'] = pd.to_numeric(df['PM2_5'], errors='coerce')\n",
            "<ipython-input-4-2bf89ac340d1>:31: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['Lat'] = pd.to_numeric(df['Lat'], errors='coerce')\n",
            "<ipython-input-4-2bf89ac340d1>:32: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['Long'] = pd.to_numeric(df['Long'], errors='coerce')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a map centered at a location within South East Asia\n",
        "map_center_sea = [10.0, 105.0]  # Choose a suitable latitude and longitude for the center\n",
        "mymap_sea = folium.Map(location=map_center_sea, zoom_start=5)  # Adjust the zoom level as needed\n",
        "\n",
        "# Add markers for each data point with PM2.5 data displayed inside the circle marker\n",
        "for index, row in df.iterrows():\n",
        "    # Determine the AQI category based on PM2.5 value\n",
        "    pm2_5 = row['PM2_5']\n",
        "    aqi_category = None\n",
        "    for category, data in aqi.items():\n",
        "        if pm2_5 >= data['pm2.5'][0] and pm2_5 <= data['pm2.5'][1]:\n",
        "            aqi_category = category\n",
        "            break\n",
        "\n",
        "    # Determine marker color based on AQI category\n",
        "    marker_color = aqi[aqi_category]['color']\n",
        "\n",
        "    # Define custom HTML content for the popup\n",
        "    popup_content = \"\"\"\n",
        "    <div style=\"max-width: 300px;\">\n",
        "        <b>DateTime:</b> {}<br>\n",
        "        <b>PM2.5:</b> {}<br>\n",
        "        <b>AQI:</b> {}<br>\n",
        "        <b>Temperature:</b> {}<br>\n",
        "        <b>Humidity:</b> {}<br>\n",
        "        <b>Altitude:</b> {}<br>\n",
        "    </div>\n",
        "    \"\"\".format(row['DateTime'], pm2_5, aqi_category, row['Temp'], row['Humi'], row['Alt'])\n",
        "\n",
        "    # Add CircleMarker with the specified radius\n",
        "    folium.CircleMarker(\n",
        "        location=[row['Lat'], row['Long']],\n",
        "        radius=5,  # Adjust the size of the marker\n",
        "        color=marker_color,\n",
        "        fill=True,\n",
        "        fill_color=marker_color,\n",
        "        fill_opacity=1,\n",
        "        popup=folium.Popup(popup_content, max_width=300),\n",
        "    ).add_to(mymap_sea)\n",
        "\n",
        "    # Add text to display PM2.5 value inside the circle marker\n",
        "    # Add text to display PM2.5 value near the circle marker\n",
        "    # Add text to display PM2.5 value above the circle marker\n",
        "    folium.Marker(\n",
        "        location=[row['Lat'], row['Long']],\n",
        "        icon=folium.DivIcon(\n",
        "            icon_size=(0, 0),  # Set icon size to zero to hide the marker\n",
        "            #html=f\"<div style='color: black; font-size: 8px; position: relative; bottom: 20px; left: 50%; transform: translateX(-50%); display: inline-block;'>{pm2_5}</div>\",\n",
        "        )\n",
        "    ).add_to(mymap_sea)\n",
        "\n",
        "\n",
        "\n",
        "# Add a legend for AQI categories\n",
        "legend_html = \"\"\"\n",
        "<div style=\"position: fixed;\n",
        "            bottom: 50px; left: 50px; width: 300px;\n",
        "            border: 2px solid grey; z-index:9999; font-size:14px;\n",
        "            background-color:white; opacity: 0.9;\">\n",
        "    <div style=\"padding-left: 10px;\">\n",
        "        <b>AQI Legend</b>\n",
        "    </div>\n",
        "    <ul style=\"list-style-type: none; padding-left: 20px; margin: 0;\">\n",
        "        <li><i class=\"fa fa-circle\" style=\"color:#006400\"></i>&nbsp; Good</li>\n",
        "        <li><i class=\"fa fa-circle\" style=\"color:#FFD700\"></i>&nbsp; Moderate</li>\n",
        "        <li><i class=\"fa fa-circle\" style=\"color:#FF8C00\"></i>&nbsp; Unhealthy for Sensitive Groups</li>\n",
        "        <li><i class=\"fa fa-circle\" style=\"color:red\"></i>&nbsp; Unhealthy</li>\n",
        "        <li><i class=\"fa fa-circle\" style=\"color:purple\"></i>&nbsp; Very Unhealthy</li>\n",
        "        <li><i class=\"fa fa-circle\" style=\"color:maroon\"></i>&nbsp; Hazardous</li>\n",
        "    </ul>\n",
        "</div>\n",
        "\"\"\"\n",
        "mymap_sea.get_root().html.add_child(folium.Element(legend_html))\n",
        "\n",
        "# Save the map as an HTML file\n",
        "mymap_sea.save(\"/content/gdrive/My Drive/Colab Notebooks/projects/thesis_dust-box_from-20240106/graph/\" + file_name + \"_filtered_data_map_sea.html\")"
      ],
      "metadata": {
        "id": "5MHgp5znmbFu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}